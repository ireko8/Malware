import gc
import pickle
from multiprocessing import Pool
import feather
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.preprocessing import LabelEncoder
from scipy.special import erfinv
from config import conf
from utils import load_csv


def standerd_scale(df):
    """ standard scaling
    """
    df = df.replace(np.inf, np.nan)
    df = df.replace(-np.inf, np.nan)
    df = (df - df.mean(axis=0)) / df.std(axis=0)
    df = df.replace(np.nan, 0)
    return df


def rankgauss(df):
    # onehot_mask = df.apply(lambda x: len(x.unique()), axis=0)
    # num_cols = df.columns[onehot_mask > 2]
    df = df.replace(np.inf, np.nan)
    df = df.replace(-np.inf, np.nan)
    # num_df = df[num_cols]
    num_df = df
    num_df = num_df.replace(np.nan, 0)
    # print("ranking...")
    num_df = num_df.rank(axis=0) / num_df.shape[0]
    # print("scaling...")
    num_df = 2 * num_df - 1
    # print("replace min/max values")
    num_df = num_df.replace(-1, -0.99999)
    num_df = num_df.replace(1, 0.99999)
    # print("erfinv")
    num_df = erfinv(num_df)
    # df[num_cols] = num_df
    return num_df


def preprocess_num(df, onehot=False, dump=None, train_col=True):
    if train_col:
        except_id = df.columns[df.columns != "train"]
        new_df = df[except_id]
        # new_df = remove_feature(new_df)
        new_df = rankgauss(new_df)
        df = pd.concat([new_df, df.train], axis=1)
    else:
        df = rankgauss(df)

    # print(df.isnull().sum().sum())
    df = df.replace(np.nan, 0)
    return df


def make_embedded_conf(df, embed_min, config, prep=True):
    """Make embedding configuration.
    configure embedded size for each column of data
    and convert data to the number corresponding to embedding
    """
    embedd_config = list()
    num_cols = config.num_cols + ["train"]
    num_df = df[num_cols].fillna(0)
    if prep:
        num_df = preprocess_num(df[num_cols])

    num_conf = {}
    fs = num_df.columns
    fs = fs.drop("train")
    gc.collect()

    fs_size = len(fs)
    layer_size = 10
    num_conf["cont"] = [fs, fs_size, layer_size]

    for c in tqdm(config.cat_cols):
        df[c] = df[c].astype(str)
        train_cats = df.loc[df.train == 1, c].unique()
        test_cats = df.loc[df.train == 0, c].unique()
        is_cats = np.intersect1d(train_cats, test_cats)
        df.loc[~df[c].isin(is_cats), c] = "nan"
        df[c] = LabelEncoder().fit_transform(df[c])
        df[c], _ = pd.factorize(df[c])
        value_dim = max(df[c]) + 1
        embedded_col_config = [c, value_dim, embed_min]
        embedd_config.append(embedded_col_config)

    conf = embedd_config, num_conf
    df = pd.concat([df[config.cat_cols], num_df], axis=1)
    del num_df

    return df, conf


def preprocess_for_nn(df, onehot=False, dump=None, train_col=True):
    if train_col:
        except_id = df.columns[df.columns != "train"]
        # new_df = df[except_id]
        # new_df = remove_feature(new_df)
        # new_df = rankgauss(new_df)
        df.loc[df.train == 1, except_id] = rankgauss(df.loc[df.train == 1, except_id])
        df.loc[df.train == 0, except_id] = rankgauss(df.loc[df.train == 0, except_id])
        # df = df.reset_index(drop=True)
        # df = pd.concat([new_df, df.train], axis=1)
    else:
        df = standerd_scale(df)

    # print(df.isnull().sum().sum())
    df = df.replace(np.nan, 0)
    return df


def prep_for_each_col(c, config):
    X_train = feather.read_dataframe('features/X_train_nejumi.ftr', columns=[c])
    X_test = feather.read_dataframe('features/X_test_nejumi.ftr', columns=[c])

    X_train["train"] = 1
    X_test["train"] = 0
    df = pd.concat([X_train, X_test])
    embed_min = 6

    if c in config.num_cols:
        col_type = 'num'
        df = preprocess_for_nn(df)
        # embedded_col_config = None
        embedded_col_config = [c, 1, embed_min]
    elif c in config.cat_cols:
        df[c] = df[c].astype(str)
        train_cats = df.loc[df.train == 1, c].unique()
        test_cats = df.loc[df.train == 0, c].unique()
        is_cats = np.intersect1d(train_cats, test_cats)
        print(c, len(train_cats))
        df.loc[~df[c].isin(is_cats), c] = "nan"
        df[c] = LabelEncoder().fit_transform(df[c])
        df[c], _ = pd.factorize(df[c])
        value_dim = max(df[c]) + 1
        embed_size = int(max(embed_min, np.sqrt(value_dim)))
        embedded_col_config = [c, value_dim, embed_size]
        col_type = 'cat'

    X_train = df[df.train == 1].drop("train", axis=1)
    X_test = df[df.train == 0].drop("train", axis=1)

    X_train.to_feather(f"features/NN/train_nejumi_v4/{c}.ftr")
    X_test.to_feather(f"features/NN/test_nejumi_v4/{c}.ftr")
    return col_type, embedded_col_config


def prep_for_embedding(config):

    cols = config.num_cols + config.cat_cols

    num_conf = dict()
    fs_size = len(config.num_cols)
    layer_size = 128
    num_conf["cont"] = [config.num_cols, fs_size, layer_size]

    arg_list = [(c, config) for c in cols]
    embedd_config = list()
    with Pool(16) as p:
        embedd_config = p.starmap(prep_for_each_col, arg_list)

    embedd_config = [x[1] for x in embedd_config if x[0] != 'num']
    conf = embedd_config, num_conf
    with open("features/NN/conf_nejumi_v4.pkl", "wb") as p:
        pickle.dump(conf, p)


if __name__ == "__main__":
    prep_for_embedding(conf)
