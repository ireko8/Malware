import gc
from pprint import pformat
from pathlib import Path
import numpy as np
import pandas as pd
from sklearn.metrics import roc_auc_score
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from NN.autoencoder import DAE
from NN.autoencoder import get_NN
from NN.autoencoder import mix_generator_v3
from utils import rank_average
from nn_utils.manager import NNManager
from nn_utils.neural import df_to_list
from keras.utils import plot_model
from ae_config import conf


def proc_autoencoder(X, logger, cv_path, nn_conf):
    batch_size = 2048
    # X = X.sample(1000000)
    num_epoch = 1  # 1000 original
    logger.info(f"hidden size {conf.ae_hls}")
    logger.info(f"swap_rate {conf.swap_rate}")
    gen = mix_generator_v3(X, batch_size, nn_conf, swaprate=conf.swap_rate)
    input_size = nn_conf[1]['cont'][1]
    dae = DAE(input_size, conf.ae_hls)
    # dae, encoders = get_DAE(X.shape[1])
    with open(cv_path / "AutoEncoder.txt", "w") as fp:
        dae.summary(print_fn=lambda x: fp.write(x + "\n"))
    plot_model(dae, to_file=str(cv_path / "arch.png"))

    callbacks = [
        EarlyStopping(
            monitor="loss", patience=10, verbose=1, min_delta=0.0001, mode="min"
        ),
        ReduceLROnPlateau(
            monitor="loss",
            factor=0.1,
            patience=5,
            verbose=1,
            min_delta=0.0001,
            mode="min",
        ),
        ModelCheckpoint(
            monitor="loss",
            filepath=str(str(cv_path / "dae.h5")),
            save_best_only=True,
            save_weights_only=True,
            mode="min",
        ),
    ]
    dae.fit_generator(
        generator=gen,
        steps_per_epoch=np.ceil(X.shape[0] / batch_size),
        use_multiprocessing=True,
        workers=16,
        epochs=num_epoch,
        verbose=1,
        callbacks=callbacks,
    )
    return dae


def prep_for_ae(X_train, X_test, cv_path, logger, nn_conf, simple=False):

    df = pd.concat([X_train, X_test])
    del X_train, X_test
    gc.collect()
    # df = preprocess_for_nn(df, dump='all')

    logger.info("make onehot")
    # df, conf = make_onehot_with_split(df)
    # df = make_onehot(df, cat_cols=conf.cat_cols)
    # cat_cols = config.cat_cols_804 + config.tam_cat_cols
    # df = make_onehot(df, cat_cols)
    cols = df.columns
    logger.info(cols)
    logger.info("done")

    logger.info("autoencoder start")
    dae = proc_autoencoder(df, logger, cv_path, nn_conf)
    logger.info("done")

    logger.info("encoding...")

    return dae


def proc_each_fold(
    nn_conf, encoders, X_train, y_train, X_valid, y_valid, X_test, seed_path, logger
):
    # dae = proc_autoencoder(pd.concat([X_train, X_valid, X_test]).values)
    # dae = proc_autoencoder(X_test.values)
    model = get_NN(X_train.shape[1], encoders)

    # Fit model
    def gen(x):
        return df_to_list(x, nn_conf)[-1]

    nnm = NNManager(seed_path, model, 2048, X_train.columns, logger, proc_per_gen=gen)
    nnm.learn(X_train, y_train, X_valid, y_valid, epochs=25)
    train_oof = nnm.predict_generator(X_valid)
    pred = nnm.predict_generator(X_test)

    return train_oof, pred


def AE_cv(
    X_train,
    y_train,
    folds,
    logger,
    cv_path,
    split_conf=None,
    X_test=None,
    optional_data=None,
):
    scores = []
    preds = []
    meta = np.zeros_like(y_train).astype("float64")
    dae = prep_for_ae(X_train, X_test, cv_path, logger, split_conf)
    logger.info(pformat(X_train.columns))

    for num_fold, (tr_ind, tes_ind) in enumerate(folds):
        if num_fold > 0:
            break
        logger.info(f"fold_{num_fold}")
        X_cv_train, X_cv_test = X_train.iloc[tr_ind], X_train.iloc[tes_ind]
        y_cv_train, y_cv_test = y_train.iloc[tr_ind], y_train.iloc[tes_ind]

        fold_path = cv_path / f"fold{num_fold}"

        Path(fold_path).mkdir(parents=True, exist_ok=True)
        train_oof, pred = proc_each_fold(
            split_conf,
            dae,
            X_cv_train,
            y_cv_train,
            X_cv_test,
            y_cv_test,
            X_test,
            fold_path,
            logger,
        )
        pred = pred[:, 0]
        np.save(fold_path / f"pred.npy", pred)

        train_oof = train_oof[:, 0]
        auc = roc_auc_score(y_cv_test.values, train_oof)
        np.save(fold_path / f"train_oof.npy", train_oof)

        logger.info(f"fold {num_fold}: auc {auc}")
        scores.append(auc)
        np.save(fold_path / f"tes_ind.npy", tes_ind)
        meta[tes_ind] += train_oof

        preds.append(pred)

    scores = np.array(scores)
    preds = np.array(preds)
    pred = rank_average(preds)
    logger.info(f"{scores.mean()}, {scores.std()}")
    return scores, pred, meta
