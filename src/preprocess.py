import gc
from multiprocessing import Pool
import numpy as np
import pandas as pd
import feather
import utils
from sklearn.preprocessing import LabelEncoder
from config import conf
from tqdm import tqdm


def wrap_preprocess(func, group_col, target_col, **kwargs):
    if type(group_col) is not list:
        group_col = [group_col]
    if type(target_col) is not list:
        target_col = [target_col]
    usecols = group_col + target_col
    train_fs = list()
    test_fs = list()
    for c in usecols:
        fs = feather.read_dataframe(f'features/train/{c}.ftr')
        train_fs.append(fs)
        fs = feather.read_dataframe(f'features/test/{c}.ftr')
        test_fs.append(fs)
    train = pd.concat(train_fs, axis=1)
    test = pd.concat(test_fs, axis=1)
    train['is_test'] = False
    test['is_test'] = True
    df = pd.concat([train, test]).reset_index(drop=True)
    orig_len = len(df)
    orig_columns = list(df.columns)
    df = func(df, group_col, **kwargs)

    assert(len(df) == orig_len)
    train = df.loc[~df.is_test].drop(orig_columns + ['is_test'], axis=1)
    train = train.reset_index(drop=True)
    test = df.loc[df.is_test].drop(orig_columns + ['is_test'], axis=1)
    test = test.reset_index(drop=True)
    for c in tqdm(train.columns, desc='dump features'):
        train[[c]].to_feather(f'features/train/{c}.ftr')
        test[[c]].to_feather(f'features/test/{c}.ftr')


def split_version(row, i):
    splitted = row.split('.')
    if len(splitted) <= i:
        ans = -1
    else:
        ans = splitted[i]
    return ans


def _aggregation(df, group_col, agg):
    if isinstance(group_col, list):
        group_col_name = '_'.join(group_col)
    else:
        group_col_name = group_col
    df[group_col] = df[group_col].astype('category')
    agged = df.groupby(group_col).agg(agg)
    agged.columns = ["_".join(x) for x in agged.columns.ravel()]
    agged.columns = [f"{group_col_name}_{c}" for c in agged.columns]
    agged = agged.reset_index()
    df = df.merge(agged, on=group_col, how='left')
    return df


def aggregate(group_col, agg_dict):
    wrap_preprocess(_aggregation, group_col, list(agg_dict.keys()),
                    agg=agg_dict)


def entropy(x):
    vec = x.value_counts(normalize=True).values
    return np.dot(vec, np.log1p(vec))


def _make_grouped_entropy(df, group, target):
    if len(group) == 1:
        group = group[0]
    entropy_col_name = f'{group}_entropy_{target}'
    x = df.groupby(group)[target].apply(entropy)
    x = x.reset_index().rename(columns={target: entropy_col_name})
    df = df.merge(x, on=group, how='left')
    return df


def make_grouped_entropy(group, target):
    wrap_preprocess(_make_grouped_entropy, group, target, target=target)


def _version_fs(df, group, i):
    if type(group) is list:
        group = group[0]
    df[group] = df[group].astype(str)

    def slice(row):
        return split_version(row, i)

    version_splitted = df[group].apply(slice)
    df[f'{group}_{i}'] = version_splitted
    if group == 'OsBuildLab':
        df[f'{group}_{i}'] = df[f'{group}_{i}'].astype('str')
    le = LabelEncoder()
    x = le.fit_transform(df[f'{group}_{i}'])
    df[f'{group}_{i}'] = pd.Series(x)
    return df


def version_fs(group, i):
    wrap_preprocess(_version_fs, group, [], i=i)


def _version_le(df, group):
    if type(group) is list:
        group = group[0]
    df[group] = df[group].astype(str)

    le = LabelEncoder()
    x = le.fit_transform(df[f'{group}'])
    df[f'{group}_le'] = pd.Series(x)
    return df


def version_le(group):
    wrap_preprocess(_version_le, group, [])


def load_df(debug=False):
    train = utils.load_feather()
    test = utils.load_feather(test=True)
    if debug:
        # train = train[:1000].copy()
        # test = test[:1000].copy()
        train = train.sample(10000).copy()
        test = test.sample(10000).copy()
    test['HasDetections'] = -1
    train['is_test'] = False
    test['is_test'] = True
    df = pd.concat([train, test]).reset_index(drop=True)
    # df = df.drop(conf.drop_cols, axis=1)
    return df


def _numeric_fs(df, group):
    df['primary_drive_c_ratio'] = df['Census_SystemVolumeTotalCapacity'] / df['Census_PrimaryDiskTotalCapacity']
    df['non_primary_drive_MB'] = df['Census_PrimaryDiskTotalCapacity'] - df['Census_SystemVolumeTotalCapacity']

    df['aspect_ratio'] = df['Census_InternalPrimaryDisplayResolutionHorizontal'] / df['Census_InternalPrimaryDisplayResolutionVertical']

    df['monitor_dims'] = df['Census_InternalPrimaryDisplayResolutionHorizontal'].astype(str) + '*' + df['Census_InternalPrimaryDisplayResolutionVertical'].astype('str')
    df['monitor_dims'] = df['monitor_dims'].astype('category')

    df['dpi'] = ((df['Census_InternalPrimaryDisplayResolutionHorizontal']**2 + df['Census_InternalPrimaryDisplayResolutionVertical']**2)**.5)/(df['Census_InternalPrimaryDiagonalDisplaySizeInInches'])

    # df['dpi_square'] = df['dpi'] ** 2

    df['MegaPixels'] = (df['Census_InternalPrimaryDisplayResolutionHorizontal'] * df['Census_InternalPrimaryDisplayResolutionVertical'])/1e6

    df['Screen_Area'] = (df['aspect_ratio']* (df['Census_InternalPrimaryDiagonalDisplaySizeInInches']**2))/(df['aspect_ratio']**2 + 1)

    df['ram_per_processor'] = df['Census_TotalPhysicalRAM'] / df['Census_ProcessorCoreCount']

    df['new_num_0'] = df['Census_InternalPrimaryDiagonalDisplaySizeInInches'] / df['Census_ProcessorCoreCount']

    df['new_num_1'] = df['Census_ProcessorCoreCount'] * df['Census_InternalPrimaryDiagonalDisplaySizeInInches']
    
    # df['Census_IsFlightingInternal'] = df['Census_IsFlightingInternal'].fillna(1)
    df['Census_ThresholdOptIn'] = df['Census_ThresholdOptIn'].fillna(1)
    df['Census_IsWIMBootEnabled'] = df['Census_IsWIMBootEnabled'].fillna(1)
    df['Wdft_IsGamer'] = df['Wdft_IsGamer'].fillna(0)
    return df


def numeric_fs():
    group = ['Census_SystemVolumeTotalCapacity', 'Census_PrimaryDiskTotalCapacity',
             'Census_InternalPrimaryDisplayResolutionHorizontal',
             'Census_InternalPrimaryDisplayResolutionVertical',
             'Census_InternalPrimaryDiagonalDisplaySizeInInches',
             'Census_TotalPhysicalRAM', 'Census_ProcessorCoreCount',
             'Census_ThresholdOptIn', 'Census_IsWIMBootEnabled', 'Wdft_IsGamer']
    wrap_preprocess(_numeric_fs, group, [])


def preprocess():

    print('entropy', utils.now())
    arg_list = []
    for g in ['CityIdentifier', 'OrganizationIdentifier']:
        for c in ['Census_OEMNameIdentifier',
                  'Census_FirmwareManufacturerIdentifier']:
            arg_list.append((g, c))

    # with Pool(4) as p:
    #     p.starmap(make_grouped_entropy, arg_list)
    gc.collect()

    print('split version', utils.now())
    dcol = ['EngineVersion', 'AppVersion', 'AvSigVersion', 'OsBuildLab',
            'Census_OSVersion']
    # with Pool(5) as p:
    #     p.map(version_le, dcol)
    arg_list = list()
    for c in dcol:
        if c == 'OsBuildLab':
            length = 5
        else:
            length = 4
        for i in range(length):
            arg_list.append((c, i))

    # with Pool(18) as p:
    #     p.starmap(version_fs, arg_list)
    # numeric_fs()
    cat_cols = [k for k, v in conf.dtypes.items() if v == 'category']
    cat_cols += [k for k, v in conf.dtypes.items() if v == 'int16']
    cat_cols += ['RtpStateBitfield',
                 'AVProductStatesIdentifier', 'AVProductsInstalled', 'AVProductsEnabled',
                 'CityIdentifier', 'OrganizationIdentifier', 'GeoNameIdentifier',
                 'SMode', 'IeVerIdentifier', 'Firewall', 'UacLuaenable',
                 'Census_OEMNameIdentifier', 'Census_OEMModelIdentifier',
                 'Census_ProcessorManufacturerIdentifier',
                 'Census_ProcessorModelIdentifier',
                 'Census_OSInstallLanguageIdentifier', 'Census_ThresholdOptIn',
                 'Census_FirmwareManufacturerIdentifier',
                 'Census_FirmwareVersionIdentifier', 'Census_IsWIMBootEnabled',
                 'Census_IsVirtualDevice', 'Census_IsAlwaysOnAlwaysConnectedCapable',
                 'Wdft_IsGamer', 'Wdft_RegionIdentifier']
    cat_cols = []
    for c in ['EngineVersion', 'AppVersion', 'AvSigVersion', 'OsBuildLab',
              'Census_OSVersion']:
        if c == 'OsBuildLab':
            length = 5
        else:
            length = 4
        for i in range(length):
            cat_cols.append(f'{c}_{i}')
            aggregate(f'{c}_{i}', {'MachineIdentifier': ['count']})
    # cat_cols = [
    #     ["AvSigVersion", "Wdft_IsGamer"],
    #     ["Census_ProcessorCoreCount",
    #      "Wdft_RegionIdentifier"],
    #     ["Census_ProcessorCoreCount",
    #      "Census_OEMNameIdentifier",
    #      "CityIdentifier"],
    #     ["Census_ProcessorCoreCount",
    #      "Census_OEMNameIdentifier",
    #      "GeoNameIdentifier"],
    #     ["GeoNameIdentifier",
    #      "Census_OEMNameIdentifier",
    #      "Census_OSBuildRevision"]]
    arg_list = list()
    cat_cols = [
        ["AvSigVersion", "Wdft_IsGamer"],
        ["Census_ProcessorCoreCount",
         "Wdft_RegionIdentifier"],
        ["Census_ProcessorCoreCount",
         "Census_OEMNameIdentifier",
         "CityIdentifier"],
        ["Census_ProcessorCoreCount",
         "Census_OEMNameIdentifier",
         "GeoNameIdentifier"],
        ["GeoNameIdentifier",
         "Census_OEMNameIdentifier",
         "Census_OSBuildRevision"]]
    for c in tqdm(cat_cols, desc='count'):
        arg_list.append((c, {'MachineIdentifier': ['count']}))
        # aggregate(c, {'MachineIdentifier': ['count']})
        
    # with Pool(2) as p:
    #     p.starmap(aggregate, arg_list)
    print('aggs', utils.now())
    geo_aggs = {'Census_OEMNameIdentifier': ['nunique'],
                'Census_FirmwareManufacturerIdentifier': ['nunique'],
                'Census_IsPenCapable': ['mean', 'var'],
                'Census_IsTouchEnabled': ['mean', 'var'],
                'Wdft_IsGamer': ['mean', 'var'],
                'dpi': ['mean', 'var'],
                'Census_ProcessorCoreCount': ['mean', 'var'],
                'Wdft_RegionIdentifier': ['nunique'],
                'Census_PrimaryDiskTotalCapacity': ['mean', 'var']}
    # aggregate('CityIdentifier', geo_aggs)
    # aggregate('OrganizationIdentifier', geo_aggs)

    oem_aggs = {'Census_FirmwareManufacturerIdentifier': ['nunique'],
                'Census_IsPenCapable': ['mean', 'var'],
                'Census_IsTouchEnabled': ['mean', 'var'],
                'Wdft_IsGamer': ['mean', 'var'],
                'dpi': ['mean', 'var'],
                'Census_ProcessorCoreCount': ['mean', 'var'],
                'Wdft_RegionIdentifier': ['nunique'],
                'Census_PrimaryDiskTotalCapacity': ['mean', 'var']}
    # aggregate('Census_OEMNameIdentifier', oem_aggs)
    
    firm_aggs = {
                 'Census_IsPenCapable': ['mean', 'var'],
                 'Census_IsTouchEnabled': ['mean', 'var'],
                 'Wdft_IsGamer': ['mean', 'var'],
                 'dpi': ['mean', 'var'],
                 'Census_ProcessorCoreCount': ['mean', 'var'],
                 'Wdft_RegionIdentifier': ['nunique'],
                 'Census_PrimaryDiskTotalCapacity': ['mean', 'var']}
    # aggregate('Census_FirmwareManufacturerIdentifier', firm_aggs)
    print('done', utils.now())


def save_feather():
    train = utils.load_csv()
    for c in tqdm(train.columns):
        train[[c]].to_feather(f'features/train/{c}.ftr')
    test = utils.load_csv(test=True)
    for c in tqdm(test.columns):
        test[[c]].to_feather(f'features/test/{c}.ftr')


if __name__ == '__main__':
    tqdm.pandas()
    preprocess()
    # save_feather()
