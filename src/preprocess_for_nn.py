import gc
import pickle
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.preprocessing import LabelEncoder
from scipy.special import erfinv
from config import conf
from utils import load_csv


def standerd_scale(df):
    """ standard scaling
    """
    df = df.replace(np.inf, np.nan)
    df = df.replace(-np.inf, np.nan)
    df = (df - df.mean(axis=0)) / df.std(axis=0)
    df = df.replace(np.nan, 0)
    return df


def rankgauss(df):
    # onehot_mask = df.apply(lambda x: len(x.unique()), axis=0)
    # num_cols = df.columns[onehot_mask > 2]
    df = df.replace(np.inf, np.nan)
    df = df.replace(-np.inf, np.nan)
    # num_df = df[num_cols]
    num_df = df
    num_df = num_df.replace(np.nan, 0)
    print("ranking...")
    num_df = num_df.rank(axis=0) / num_df.shape[0]
    print("scaling...")
    num_df = 2 * num_df - 1
    print("replace min/max values")
    num_df = num_df.replace(-1, -0.99999)
    num_df = num_df.replace(1, 0.99999)
    print("erfinv")
    num_df = erfinv(num_df)
    # df[num_cols] = num_df
    return num_df


def preprocess_num(df, onehot=False, dump=None, train_col=True):
    if train_col:
        except_id = df.columns[df.columns != "train"]
        new_df = df[except_id]
        # new_df = remove_feature(new_df)
        new_df = standerd_scale(new_df)
        df = pd.concat([new_df, df.train], axis=1)
    else:
        df = rankgauss(df)

    print(df.isnull().sum().sum())
    df = df.replace(np.nan, 0)
    return df


def make_embedded_conf(df, embed_min, config, prep=True):
    """Make embedding configuration.
    configure embedded size for each column of data
    and convert data to the number corresponding to embedding
    """
    embedd_config = list()
    num_cols = config.num_cols + ["train"]
    num_df = df[num_cols].fillna(0)
    if prep:
        num_df = preprocess_num(df[num_cols])

    num_conf = {}
    fs = num_df.columns
    fs = fs.drop("train")
    gc.collect()

    fs_size = len(fs)
    layer_size = 10
    num_conf["cont"] = [fs, fs_size, layer_size]

    for c in tqdm(config.cat_cols):
        df[c] = df[c].astype(str)
        train_cats = df.loc[df.train == 1, c].unique()
        test_cats = df.loc[df.train == 0, c].unique()
        is_cats = np.intersect1d(train_cats, test_cats)
        df.loc[~df[c].isin(is_cats), c] = "nan"
        df[c] = LabelEncoder().fit_transform(df[c])
        df[c], _ = pd.factorize(df[c])
        value_dim = max(df[c]) + 1
        embedded_col_config = [c, value_dim, embed_min]
        embedd_config.append(embedded_col_config)

    conf = embedd_config, num_conf
    df = pd.concat([df[config.cat_cols], num_df], axis=1)
    del num_df

    return df, conf


def preprocess_for_nn(df, onehot=False, dump=None, train_col=True):
    if train_col:
        except_id = df.columns[df.columns != "train"]
        new_df = df[except_id]
        # new_df = remove_feature(new_df)
        new_df = standerd_scale(new_df)
        df = pd.concat([new_df, df.train], axis=1)
    else:
        df = standerd_scale(df)

    print(df.isnull().sum().sum())
    df = df.replace(np.nan, 0)
    return df


def prep_for_embedding(config):

    X_train = load_csv(debug=True)
    X_test = load_csv(test=True, debug=True)

    X_train["train"] = 1
    X_test["train"] = 0
    df = pd.concat([X_train, X_test])
    # df = preprocess_for_nn(df, dump='all')
    del X_train, X_test

    df, conf = make_embedded_conf(df, 6, config, prep=True)

    X_train = df[df.train == 1].drop("train", axis=1)
    X_test = df[df.train == 0].drop("train", axis=1)

    X_train.to_feather("feature/NN/train.ftr")
    X_test.to_feather("feature/NN/test.ftr")
    with open("feature/NN/conf.pkl", "wb") as p:
        pickle.dump(conf, p)


if __name__ == "__main__":
    prep_for_embedding(conf)
