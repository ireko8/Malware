import gc
from functools import partial
from collections import defaultdict
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.preprocessing import LabelEncoder, LabelBinarizer
from scipy.special import erfinv


def intersect_categorize(df, c, embed_min):
    df[c] = df[c].astype(str).fillna('nan')
    train_cats = df.loc[df.train == 1, c].unique()
    test_cats = df.loc[df.train == 0, c].unique()
    is_cats = np.intersect1d(train_cats, test_cats)
    df.loc[~df[c].isin(is_cats), c] = 'nan'
    df[c], _ = pd.factorize(df[c])
    value_dim = max(df[c]) + 1
    embedded_col_config = [c, value_dim, embed_min]

    return df, embedded_col_config


def standerd_scale(df):
    """ standard scaling
    """
    df = df.replace(np.inf, np.nan)
    df = df.replace(-np.inf, np.nan)
    df = (df - df.mean(axis=0)) / df.std(axis=0)
    df = df.replace(np.nan, 0)
    return df


def rankgauss2(df):
    """ rankgauss implemented based on MJ's note
    """
    df = df.replace(np.inf, np.nan)
    df = df.replace(-np.inf, np.nan)
    num_df = df
    num_df = num_df.fillna(num_df.mean())

    print('ranking...')
    num_df = num_df.rank(axis=0) / num_df.shape[0]

    print('scaling...')
    num_df = 2 * num_df - 1

    print('replace min/max values')
    num_df = num_df.replace(-1, -0.99999)
    num_df = num_df.replace(1, 0.99999)

    print('erfinv')
    num_df = erfinv(num_df)

    return num_df


def rankgauss(df):
    # onehot_mask = df.apply(lambda x: len(x.unique()), axis=0)
    # num_cols = df.columns[onehot_mask > 2]
    df = df.replace(np.inf, np.nan)
    df = df.replace(-np.inf, np.nan)
    # num_df = df[num_cols]
    num_df = df
    num_df = num_df.replace(np.nan, 0)
    # print('ranking...')
    num_df = num_df.rank(axis=0) / num_df.shape[0]
    # print('scaling...')
    num_df = 2 * num_df - 1
    # print('replace min/max values')
    num_df = num_df.replace(-1, -0.99999)
    num_df = num_df.replace(1, 0.99999)
    # print('erfinv')
    num_df = erfinv(num_df)
    # df[num_cols] = num_df
    return num_df


def preprocess_for_nn(df, onehot=False, dump=None, train_col=True):
    if train_col:
        except_id = df.columns[df.columns != 'train']
        for c in tqdm(except_id):
            df.loc[df.train == 1, c] = rankgauss(df.loc[df.train == 1, c]).values
            df.loc[df.train == 0, c] = rankgauss(df.loc[df.train == 0, c]).values
            gc.collect()
    else:
        df = rankgauss(df)

    print(df.isnull().sum().sum())
    df = df.replace(np.nan, 0)
    return df


def make_emb_conf_for_rnn(df, embed_min):
    not_num_cols = [
        'HOUR_APPR_PROCESS_START', 'NFLAG_LAST_APPL_IN_DAY',
        'NFLAG_INSURED_ON_APPROVAL'
    ]
    for c in not_num_cols:
        df[c] = df[c].astype(object)

    cat_cols = df.columns[df.dtypes == object]

    num_cols = df.columns[df.dtypes != object]
    num_conf = len(num_cols), 32

    embedded_conf = list()
    for c in cat_cols:
        df[c], _ = pd.factorize(df[c])
        value_dim = df[c].max() + 2
        embedded_conf.append([c, value_dim, embed_min])
    conf = embedded_conf, num_conf
    return conf


def make_onehot(df, cat_cols=[]):
    num_cols = df.columns[~df.columns.isin(cat_cols)]
    if len(cat_cols) > 0:
        df_cat = df[cat_cols].astype(object)
        df_num = preprocess_for_nn(df[num_cols], train_col=False)
        onehot = pd.get_dummies(df_cat, dummy_na=True)
        df = pd.concat([df_num, onehot], axis=1)
    else:
        df = preprocess_for_nn(df[num_cols], train_col=False)

    return df


def make_onehot_with_split(df, config):

    conf = {}

    fs = df.columns
    conf['numerical'] = defaultdict(dict)
    conf['categorical'] = defaultdict(dict)

    for t in config.cat_cols_804:
        cat_size = len(df[t].unique())
        if df[t].isnull().sum() == 0:
            cat_size += 1
        conf['categorical'][t] = cat_size
        fs = fs.drop(t)

    for t in config.num_split_type:
        print(t)
        fst = fs[fs.str.contains(t)]
        fs = fs.drop(fst)

        fst_size = len(fst)
        if fst_size != 0:
            conf['numerical'][t] = fst

    df = make_onehot(df)

    return df, conf


def make_embedded_conf(df, embed_min, config, prep=True):
    """Make embedding configuration.
    configure embedded size for each column of data
    and convert data to the number corresponding to embedding
    """
    embedd_config = list()
    num_cols = config.num_cols + ['train']
    if prep:
        num_df = preprocess_for_nn(df[num_cols])
    else:
        num_df = df[num_cols].fillna(0)    

    num_conf = {}
    fs = num_df.columns
    fs = fs.drop('train')
    gc.collect()

    fs_size = len(fs)
    layer_size = 256
    num_conf['cont'] = [fs, fs_size, layer_size]
    
    for c in tqdm(config.cat_cols):
        df[c] = df[c].astype(str)
        train_cats = df.loc[df.train == 1, c].unique()
        test_cats = df.loc[df.train == 0, c].unique()
        is_cats = np.intersect1d(train_cats, test_cats)
        df.loc[~df[c].isin(is_cats), c] = "nan"
        df[c] = LabelEncoder().fit_transform(df[c])
        df[c], _ = pd.factorize(df[c])
        value_dim = max(df[c]) + 1
        embed_size = int(max(embed_min, np.sqrt(value_dim)))
        embedded_col_config = [c, value_dim, embed_size]
        embedd_config.append(embedded_col_config)
        
    conf = embedd_config, num_conf
    df = pd.concat([df[config.cat_cols], num_df], axis=1)
    del num_df

    return df, conf


def make_opt(X_tr, X_te, col_name):
    X_tr.name = col_name
    X_te.name = col_name
    X_tr = X_tr.to_frame()
    X_te = X_te.to_frame()
    X_tr['train'] = 1
    X_te['train'] = 0
    feature = pd.concat([X_tr, X_te])
    feature[col_name] = rankgauss(feature[col_name])
    X_tr = feature.loc[feature.train == 1, col_name]
    X_te = feature.loc[feature.train == 0, col_name]
    return X_tr, X_te


def df_to_list(df, conf, swap_noise=0, onehot=False):
    splitted_df = list()
    for c, max_ft, _ in conf[0]:        
        if onehot:
            ohe = np.zeros((len(df), max_ft))
            idx = list(zip(range(len(df)), df[c].values))
            for p in idx:
                ohe[p] = 1
            splitted_df.append(ohe)
        else:
            splitted_df.append(df[c])

    for c, v in conf[1].items():
        if swap_noise > 0:
            size = int(len(df) * swap_noise)
            for c in v[0]:
                swap = np.random.choice(len(df), 2*size)
                df.loc[swap[:size], c] = df.loc[swap[size:], c]
        splitted_df.append(df[v[0]])

    return splitted_df


def df_to_list_onehot(df, conf):
    splitted_df = list()
    for t, d in conf.items():
        if t == 'categorical':
            for col_name, size in d.items():
                cols = df.columns[df.columns.str.startswith(col_name)]
                splitted_df.append(df[cols])
        else:
            for col_pref, cols in d.items():
                splitted_df.append(df[cols])

    return splitted_df


def prep_for_embedding(X_train, X_test, config, simple=False, prep=True):

    X_train['train'] = 1
    X_test['train'] = 0
    df = pd.concat([X_train, X_test])
    # df = preprocess_for_nn(df, dump='all')
    del X_train, X_test

    print("make embedd conf")
    df, conf = make_embedded_conf(df, 6, config, prep=prep)
    print("done")

    X_train = df[df.train == 1].drop('train', axis=1)
    X_test = df[df.train == 0].drop('train', axis=1)

    assert ((X_train.columns == X_test.columns).all())
    assert (not X_train.isnull().values.any())
    gc.collect()

    def generator(df):
        return df_to_list(df, conf)

    return X_train, X_test, conf, generator

