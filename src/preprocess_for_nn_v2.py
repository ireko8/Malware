import gc
import pickle
from datetime import datetime
from multiprocessing import Pool
import feather
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.preprocessing import LabelEncoder
from scipy.special import erfinv
from config_tosh import conf


def standerd_scale(df):
    """ standard scaling
    """
    df = df.replace(np.inf, np.nan)
    df = df.replace(-np.inf, np.nan)
    df = (df - df.mean(axis=0)) / df.std(axis=0)
    df = df.replace(np.nan, 0)
    return df


def rankgauss(df):
    # onehot_mask = df.apply(lambda x: len(x.unique()), axis=0)
    # num_cols = df.columns[onehot_mask > 2]
    df = df.replace(np.inf, np.nan)
    df = df.replace(-np.inf, np.nan)
    # num_df = df[num_cols]
    num_df = df
    num_df = num_df.replace(np.nan, 0)
    # print("ranking...")
    num_df = num_df.rank(axis=0) / num_df.shape[0]
    # print("scaling...")
    num_df = 2 * num_df - 1
    # print("replace min/max values")
    num_df = num_df.replace(-1, -0.99999)
    num_df = num_df.replace(1, 0.99999)
    # print("erfinv")
    num_df = erfinv(num_df)
    # df[num_cols] = num_df
    return num_df


def preprocess_num(df, onehot=False, dump=None, train_col=True):
    if train_col:
        except_id = df.columns[df.columns != "train"]
        new_df = df[except_id]
        # new_df = remove_feature(new_df)
        new_df = rankgauss(new_df)
        df = pd.concat([new_df, df.train], axis=1)
    else:
        df = rankgauss(df)

    # print(df.isnull().sum().sum())
    df = df.replace(np.nan, 0)
    return df


def make_embedded_conf(df, embed_min, config, prep=True):
    """Make embedding configuration.
    configure embedded size for each column of data
    and convert data to the number corresponding to embedding
    """
    embedd_config = list()
    num_cols = config.num_cols + ["train"]
    num_df = df[num_cols].fillna(0)
    if prep:
        num_df = preprocess_num(df[num_cols])

    num_conf = {}
    fs = num_df.columns
    fs = fs.drop("train")
    gc.collect()

    fs_size = len(fs)
    layer_size = 10
    num_conf["cont"] = [fs, fs_size, layer_size]

    for c in tqdm(config.cat_cols):
        df[c] = df[c].astype(str)
        train_cats = df.loc[df.train == 1, c].unique()
        test_cats = df.loc[df.train == 0, c].unique()
        is_cats = np.intersect1d(train_cats, test_cats)
        df.loc[~df[c].isin(is_cats), c] = "nan"
        df[c] = LabelEncoder().fit_transform(df[c])
        df[c], _ = pd.factorize(df[c])
        value_dim = max(df[c]) + 1
        embedded_col_config = [c, value_dim, embed_min]
        embedd_config.append(embedded_col_config)

    conf = embedd_config, num_conf
    df = pd.concat([df[config.cat_cols], num_df], axis=1)
    del num_df

    return df, conf


def preprocess_for_nn(df, onehot=False, dump=None, train_col=True):
    if train_col:
        except_id = df.columns[~df.columns.isin(["train", "private"])]
        # new_df = df[except_id]
        # new_df = remove_feature(new_df)
        # new_df = rankgauss(new_df)
        df.loc[df.private == -1, except_id] = rankgauss(df.loc[df.private == -1, except_id])
        df.loc[df.private == 0, except_id] = rankgauss(df.loc[df.private == 0, except_id])
        df.loc[df.private == 1, except_id] = rankgauss(df.loc[df.private == 1, except_id])
        # df = df.reset_index(drop=True)
        # df = pd.concat([new_df, df.train], axis=1)
    else:
        df = standerd_scale(df)

    # print(df.isnull().sum().sum())
    df = df.replace(np.nan, 0)
    return df


def preprocess_for_concat(df, onehot=False, dump=None, train_col=True):
    if train_col:
        except_id = df.columns[~df.columns.isin(["train", "private"])]
        new_df = df[except_id]
        new_df = rankgauss(new_df)
        df = pd.concat([new_df, df.train], axis=1)
    else:
        df = standerd_scale(df)

    # print(df.isnull().sum().sum())
    df = df.replace(np.nan, 0)
    return df


def add_timestamps(df):
    datedictAS = np.load("input/AvSigVersionTimestamps.npy")[()]
    df["DateAS"] = df["AvSigVersion"].map(datedictAS)

    datedictOS = np.load("input/OSVersionTimestamps.npy")[()]
    df["DateOS"] = df["Census_OSVersion"].map(datedictOS)
    # BL timestamp

    def convert(x):
        try:
            d = datetime.strptime(x.split(".")[4], "%y%m%d-%H%M")
        except:
            d = np.nan
        return d

    df["DateBL"] = df["OsBuildLab"].map(convert)


def prep_for_each_col(c, num_cols, cat_cols):
    if "f02" in c:
        X_train = feather.read_dataframe("features/X_train_onodera002.ftr", columns=[c])
        X_test = feather.read_dataframe("features/X_test_onodera002.ftr", columns=[c])
    elif "Rank" in c:
        X_train = feather.read_dataframe("features/X_train_nejumi704.ftr", columns=[c])
        X_test = feather.read_dataframe("features/X_test_nejumi_704.ftr", columns=[c])
    else:
        X_train = feather.read_dataframe("features/X_train_onodera_nyanp.ftr", columns=[c])
        X_test = feather.read_dataframe("features/X_test_onodera_nyanp.ftr", columns=[c])

    X_train["train"] = 1
    X_test["train"] = 0
    X_train["private"] = -1
    X_test["private"] = 0
    df = pd.concat([X_train, X_test])
    embed_min = 6

    if c in num_cols:
        print(c, "num")
        col_type = "num"
        cols = ["AvSigVersion", "Census_OSVersion", "OsBuildLab"]
        train_av = feather.read_dataframe("input/train.ftr", columns=cols)
        test_av = feather.read_dataframe("input/test.ftr", columns=cols)
        timestamp = pd.concat([train_av, test_av])

        add_timestamps(timestamp)

        df.loc[
            (timestamp.DateAS >= "2018-10-26")
            | (timestamp.DateBL >= "2018-10-26")
            | (timestamp.DateOS >= "2018-10-26"),
            "private",
        ] = 1
        df = preprocess_for_nn(df)
        # embedded_col_config = None
        embedded_col_config = [c, 1, embed_min]
    elif c in cat_cols:
        df[c] = df[c].astype(str)
        train_cats = df.loc[df.train == 1, c].unique()
        test_cats = df.loc[df.train == 0, c].unique()
        is_cats = np.intersect1d(train_cats, test_cats)
        print(c, len(train_cats))
        df.loc[~df[c].isin(is_cats), c] = "nan"
        df[c] = LabelEncoder().fit_transform(df[c])
        df[c], _ = pd.factorize(df[c])
        value_dim = max(df[c]) + 1
        embed_size = int(max(embed_min, np.sqrt(value_dim)))
        embedded_col_config = [c, value_dim, embed_size]
        col_type = "cat"

    X_train = df[df.train == 1].drop(["train", "private"], axis=1)
    X_test = df[df.train == 0].drop(["train", "private"], axis=1)

    X_train.to_feather(f"features/NN/train_all_snap/{c}.ftr")
    X_test.to_feather(f"features/NN/test_all_snap/{c}.ftr")
    return col_type, embedded_col_config


def prep_for_embedding(config):

    num_cols = sum([v for v in config.num_cols.values()], [])
    cat_cols = config.cat_cols
    cols = num_cols + config.cat_cols

    num_conf = dict()
    for k, v in config.num_cols.items():
        fs_size = len(v)
        layer_size = 64
        num_conf[k] = [v, fs_size, layer_size]

    arg_list = [(c, num_cols, cat_cols) for c in cols]
    embedd_config = list()

    # for a in tqdm(arg_list):
    #     embedd_config.append(prep_for_each_col(*a))
    with Pool(16) as p:
        embedd_config = p.starmap(prep_for_each_col, arg_list)

    embedd_config = [x[1] for x in embedd_config if x[0] != "num"]
    conf = embedd_config, num_conf
    with open("features/NN/conf_tosh_all_snap.pkl", "wb") as p:
        pickle.dump(conf, p)


if __name__ == "__main__":
    prep_for_embedding(conf)
